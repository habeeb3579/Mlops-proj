# Makefile for NYC Taxi Trip Duration Prediction with MLflow
# 
# This Makefile provides shortcuts for common operations related to
# training and managing ML models for NYC taxi trip duration prediction.

# Default configuration
PYTHON := python
MODELS := all
TRAIN_YEAR := 2021
TRAIN_MONTH := 1
VAL_YEAR := 2021
VAL_MONTH := 2
TAXI_TYPE := green
TRACKING_STORE := sqlite
DB_PATH := mlflow.db
EXPERIMENT_NAME := nyc-taxi-exp-weighted
MODEL_NAME := nyc-taxi-regressor-weighted
CAT_TRANSFORMER := dict_vectorizer
NUM_TRANSFORMER := standard
TUNE := True
REGISTER := True
MAX_EVALS := 20

# Directory structure
DATA_DIR := data
MODELS_DIR := models
MLRUNS_DIR := mlruns

# Help command
help:
	@echo "NYC Taxi Trip Duration Prediction with MLflow - Makefile Commands"
	@echo ""
	@echo "Basic Commands:"
	@echo "  run-all                 Run experiment with all models"
	@echo "  run-models              Run experiment with specific models (set MODELS=model1,model2)"
	@echo "  run-custom              Run experiment with custom parameters"
	@echo "  run-quick               Run experiment with LinearRegression only (no tuning)"
	@echo "  register-models         Register best model without training"
	@echo "  serve-model             Serve the production model using MLflow"
	@echo "  mlflow-ui               Launch the MLflow UI"
	@echo ""
	@echo "Data Commands:"
	@echo "  download-data           Download NYC taxi data"
	@echo "  prepare-data            Prepare data for modeling"
	@echo ""
	@echo "Storage Commands:"
	@echo "  setup-sqlite            Set up SQLite tracking backend"
	@echo "  setup-postgres          Set up PostgreSQL tracking backend"
	@echo "  setup-aws               Set up AWS S3 tracking backend"
	@echo "  setup-gcp               Set up GCP tracking backend"
	@echo ""
	@echo "Maintenance Commands:"
	@echo "  clean                   Remove temporary files and SQLite DB"
	@echo "  clean-all               Remove all generated files including models and data"
	@echo "  requirements            Generate requirements.txt"
	@echo ""
	@echo "Environment Variables:"
	@echo "  MODELS                  Models to train (comma-separated, default: all)"
	@echo "  TRAIN_YEAR              Training data year (default: 2021)"
	@echo "  TRAIN_MONTH             Training data month (default: 1)"
	@echo "  VAL_YEAR                Validation data year (default: 2021)"
	@echo "  VAL_MONTH               Validation data month (default: 2)"
	@echo "  TAXI_TYPE               Taxi type: green or yellow (default: green)"
	@echo "  TRACKING_STORE          MLflow tracking store (default: sqlite)"
	@echo "  DB_PATH                 SQLite database path (default: mlflow.db)"
	@echo "  EXPERIMENT_NAME         MLflow experiment name (default: nyc-taxi-experiment)"
	@echo "  MODEL_NAME              Model registry name (default: nyc-taxi-regressor)"
	@echo "  CAT_TRANSFORMER         Categorical transformer (default: onehot)"
	@echo "  NUM_TRANSFORMER         Numerical transformer (default: standard)"
	@echo "  TUNE                    Enable hyperparameter tuning (default: True)"
	@echo "  REGISTER                Register best model (default: True)"
	@echo "  MAX_EVALS               Max evaluations for hyperparameter tuning (default: 20)"
	@echo ""
	@echo "Examples:"
	@echo "  make run-models MODELS=\"Ridge,XGBoost\""
	@echo "  make run-custom TRAIN_YEAR=2021 TRAIN_MONTH=3 VAL_YEAR=2021 VAL_MONTH=4 TUNE=False"
	@echo "  make setup-postgres DB_USER=mlflow_user DB_PASSWORD=secret"

# Make sure directories exist
$(DATA_DIR):
	mkdir -p $(DATA_DIR)

$(MODELS_DIR):
	mkdir -p $(MODELS_DIR)

# Basic commands
run-all: $(DATA_DIR) $(MODELS_DIR)
	$(PYTHON) -c "from mlflowpy import run_nyc_taxi_experiment; run_nyc_taxi_experiment(tracking_config={'tracking_store': '$(TRACKING_STORE)', 'db_path': '$(DB_PATH)'}, experiment_name='$(EXPERIMENT_NAME)', model_registry_name='$(MODEL_NAME)', train_year=$(TRAIN_YEAR), train_month=$(TRAIN_MONTH), val_year=$(VAL_YEAR), val_month=$(VAL_MONTH), taxi='$(TAXI_TYPE)', model_types=None, categorical_transformer='$(CAT_TRANSFORMER)', numerical_transformer='$(NUM_TRANSFORMER)', register_model=$(REGISTER), tune_hyperparams=$(TUNE))"

run-models: $(DATA_DIR) $(MODELS_DIR)
	$(PYTHON) -c "from mlflowpy import run_nyc_taxi_experiment; run_nyc_taxi_experiment(tracking_config={'tracking_store': '$(TRACKING_STORE)', 'db_path': '$(DB_PATH)'}, experiment_name='$(EXPERIMENT_NAME)', model_registry_name='$(MODEL_NAME)', train_year=$(TRAIN_YEAR), train_month=$(TRAIN_MONTH), val_year=$(VAL_YEAR), val_month=$(VAL_MONTH), taxi='$(TAXI_TYPE)', model_types=['$(subst $(comma),$(singlequote),$(MODELS))'], categorical_transformer='$(CAT_TRANSFORMER)', numerical_transformer='$(NUM_TRANSFORMER)', register_model=$(REGISTER), tune_hyperparams=$(TUNE))"

run-custom: $(DATA_DIR) $(MODELS_DIR)
	$(PYTHON) -c "from mlflowpy import run_nyc_taxi_experiment; run_nyc_taxi_experiment(tracking_config={'tracking_store': '$(TRACKING_STORE)', 'db_path': '$(DB_PATH)'}, experiment_name='$(EXPERIMENT_NAME)', model_registry_name='$(MODEL_NAME)', train_year=$(TRAIN_YEAR), train_month=$(TRAIN_MONTH), val_year=$(VAL_YEAR), val_month=$(VAL_MONTH), taxi='$(TAXI_TYPE)', model_types=['$(subst $(comma),$(singlequote),$(MODELS))'], categorical_transformer='$(CAT_TRANSFORMER)', numerical_transformer='$(NUM_TRANSFORMER)', register_model=$(REGISTER), tune_hyperparams=$(TUNE))"

run-quick: $(DATA_DIR) $(MODELS_DIR)
	$(PYTHON) -c "from mlflowpy import run_nyc_taxi_experiment; run_nyc_taxi_experiment(tracking_config={'tracking_store': '$(TRACKING_STORE)', 'db_path': '$(DB_PATH)'}, experiment_name='$(EXPERIMENT_NAME)', model_registry_name='$(MODEL_NAME)', train_year=$(TRAIN_YEAR), train_month=$(TRAIN_MONTH), val_year=$(VAL_YEAR), val_month=$(VAL_MONTH), taxi='$(TAXI_TYPE)', model_types=['LinearRegression'], categorical_transformer='$(CAT_TRANSFORMER)', numerical_transformer='$(NUM_TRANSFORMER)', register_model=True, tune_hyperparams=False)"

register-models:
	$(PYTHON) -c "from mlflowpy import ExperimentManager; manager = ExperimentManager(tracking_config={'tracking_store': '$(TRACKING_STORE)', 'db_path': '$(DB_PATH)'}, experiment_name='$(EXPERIMENT_NAME)', model_registry_name='$(MODEL_NAME)'); manager.register_best_model()"

serve-model:
	@echo "Starting MLflow model server for production model $(MODEL_NAME)"
	mlflow models serve -m "models:/$(MODEL_NAME)/Production" -p 5001

mlflow-ui:
	@echo "Starting MLflow UI with tracking store: $(TRACKING_STORE)"
	@if [ "$(TRACKING_STORE)" = "sqlite" ]; then \
		mlflow ui --backend-store-uri sqlite:///$(DB_PATH); \
	elif [ "$(TRACKING_STORE)" = "postgresql" ]; then \
		mlflow ui --backend-store-uri postgresql://$(DB_USER):$(DB_PASSWORD)@$(DB_HOST):$(DB_PORT)/$(DB_NAME); \
	else \
		mlflow ui; \
	fi

# Data commands
download-data: $(DATA_DIR)
	$(PYTHON) -c "from mlflowpy import NYCTaxiDurationExperiment; experiment = NYCTaxiDurationExperiment(data_dir='$(DATA_DIR)'); experiment.download_data($(TRAIN_YEAR), $(TRAIN_MONTH), '$(TAXI_TYPE)'); experiment.download_data($(VAL_YEAR), $(VAL_MONTH), '$(TAXI_TYPE)')"

prepare-data: download-data
	$(PYTHON) -c "from mlflowpy import NYCTaxiDurationExperiment; experiment = NYCTaxiDurationExperiment(data_dir='$(DATA_DIR)'); train_data = experiment.download_data($(TRAIN_YEAR), $(TRAIN_MONTH), '$(TAXI_TYPE)'); experiment.prepare_data(train_data); val_data = experiment.download_data($(VAL_YEAR), $(VAL_MONTH), '$(TAXI_TYPE)'); experiment.prepare_data(val_data)"

# Storage commands
setup-sqlite:
	@echo "Setting up SQLite tracking backend at $(DB_PATH)"
	$(PYTHON) -c "import mlflow; mlflow.set_tracking_uri('sqlite:///$(DB_PATH)')"

setup-postgres:
	@echo "Setting up PostgreSQL tracking backend"
	$(PYTHON) -c "import mlflow; mlflow.set_tracking_uri('postgresql://$(DB_USER):$(DB_PASSWORD)@$(DB_HOST):$(DB_PORT)/$(DB_NAME)')"

setup-aws:
	@echo "Setting up AWS S3 tracking backend"
	$(PYTHON) -c "import mlflow; from mlflowpy import StorageConfig; tracking_uri = StorageConfig.get_tracking_uri('aws', s3_bucket='$(S3_BUCKET)', region='$(AWS_REGION)'); mlflow.set_tracking_uri(tracking_uri)"

setup-gcp:
	@echo "Setting up GCP tracking backend"
	$(PYTHON) -c "import mlflow; from mlflowpy import StorageConfig; tracking_uri = StorageConfig.get_tracking_uri('gcp', project='$(GCP_PROJECT)', bucket='$(GCP_BUCKET)'); mlflow.set_tracking_uri(tracking_uri)"

# Maintenance commands
clean:
	@echo "Cleaning up temporary files"
	rm -f $(DB_PATH)
	rm -f *.pyc
	rm -rf __pycache__

clean-all: clean
	@echo "Cleaning up all generated files"
	rm -rf $(MLRUNS_DIR)
	rm -rf $(MODELS_DIR)
	# Keeping data directory because downloads might be time-consuming
	# Add --force flag to remove data as well
	if [ "$(force)" = "true" ]; then rm -rf $(DATA_DIR); fi

requirements:
	@echo "Generating requirements.txt"
	@echo "mlflow>=2.0.0" > requirements.txt
	@echo "scikit-learn>=1.0.0" >> requirements.txt
	@echo "xgboost>=1.5.0" >> requirements.txt
	@echo "pandas>=1.3.0" >> requirements.txt
	@echo "numpy>=1.20.0" >> requirements.txt
	@echo "hyperopt>=0.2.5" >> requirements.txt
	@echo "psycopg2-binary>=2.9.0  # For PostgreSQL support" >> requirements.txt
	@echo "boto3>=1.24.0  # For AWS support" >> requirements.txt
	@echo "google-cloud-storage>=2.0.0  # For GCP support" >> requirements.txt

# Variables for command substitution
comma := ,
singlequote := '
subst = $(subst $(comma),$(singlequote),$(1))

.PHONY: help run-all run-models run-custom run-quick register-models serve-model mlflow-ui download-data prepare-data setup-sqlite setup-postgres setup-aws setup-gcp clean clean-all requirements